{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping kost data from olx.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import time\n",
    "import pyprind\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "os.environ['WDM_SSL_VERIFY']='0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all url from specific locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link0  = 'https://www.olx.co.id/indekos_c4833?sorting=desc-creation'\n",
    "link1  = 'https://www.olx.co.id/jakarta-selatan_g4000030/indekos_c4833'\n",
    "link2  = 'https://www.olx.co.id/jakarta-barat_g4000028/indekos_c4833'\n",
    "link3  = 'https://www.olx.co.id/jakarta-pusat_g4000029/indekos_c4833'\n",
    "link4  = 'https://www.olx.co.id/jakarta-timur_g4000031/indekos_c4833'\n",
    "link5  = 'https://www.olx.co.id/jakarta-utara_g4000032/indekos_c4833'\n",
    "link6  = 'https://www.olx.co.id/surabaya-kota_g4000216/indekos_c4833'\n",
    "link7  = 'https://www.olx.co.id/malang-kota_g4000212/indekos_c4833'\n",
    "link8  = 'https://www.olx.co.id/sidoarjo-kab_g4000202/indekos_c4833'\n",
    "link9  = 'https://www.olx.co.id/malang-kab_g4000192/indekos_c4833'\n",
    "link10 = 'https://www.olx.co.id/bandung-kota_g4000018/indekos_c4833'\n",
    "link11 = 'https://www.olx.co.id/bekasi-kota_g4000020/indekos_c4833'\n",
    "link12 = 'https://www.olx.co.id/depok-kota_g4000024/indekos_c4833'\n",
    "link13 = 'https://www.olx.co.id/bekasi-kab_g4000003/indekos_c4833'\n",
    "link14 = 'https://www.olx.co.id/bogor-kab_g4000004/indekos_c4833'\n",
    "link15 = 'https://www.olx.co.id/bogor-kota_g4000021/indekos_c4833'\n",
    "link16 = 'https://www.olx.co.id/tangerang-selatan-kota_g4000080/indekos_c4833'\n",
    "link17 = 'https://www.olx.co.id/tangerang-kota_g4000079/indekos_c4833'\n",
    "link18 = 'https://www.olx.co.id/tangerang-kab_g4000076/indekos_c4833'\n",
    "link19 = 'https://www.olx.co.id/sleman-kab_g4000071/indekos_c4833'\n",
    "link20 = 'https://www.olx.co.id/yogyakarta-kota_g4000072/indekos_c4833'\n",
    "link21 = 'https://www.olx.co.id/bantul-kab_g4000068/indekos_c4833'\n",
    "link22 = 'https://www.olx.co.id/semarang-kota_g4000065/indekos_c4833'\n",
    "link23 = 'https://www.olx.co.id/surakarta-kota_g4000066/indekos_c4833'\n",
    "link24 = 'https://www.olx.co.id/denpasar-kota_g4000225/indekos_c4833'\n",
    "link25 = 'https://www.olx.co.id/kab-badung_g4000217/indekos_c4833'\n",
    "link26 = 'https://www.olx.co.id/medan-kota_g4000131/indekos_c4833'\n",
    "link27 = 'https://www.olx.co.id/bandar-lampung-kota_g4000382/indekos_c4833'\n",
    "link28 = 'https://www.olx.co.id/palembang-kota_g4000368/indekos_c4833'\n",
    "link29 = 'https://www.olx.co.id/kalimantan-selatan_g2000013/indekos_c4833'\n",
    "link30 = 'https://www.olx.co.id/aceh-di_g2000001/indekos_c4833'\n",
    "link31 = 'https://www.olx.co.id/kalimantan-timur_g2000015/indekos_c4833'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all url using sellenium\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get(link31)\n",
    "\n",
    "kos_urls = []\n",
    "ads = 3000 # total kost ads u want to scrap, or u can found from total ads that the web said\n",
    "max_loop = int(ads / 20)\n",
    "\n",
    "# load all ads\n",
    "for val in range(max_loop):\n",
    "    load_more = driver.find_element_by_xpath(\"//span[.='muat lainnya']\")\n",
    "    time.sleep(1)\n",
    "    load_more.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get link using beautifulsoup\n",
    "html = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "all_links = html.find_all('li', class_='EIR5N')\n",
    "# len(all_links)\n",
    "for link in all_links:\n",
    "    kos_urls.append('https://www.olx.co.id'+ link.a['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 152\n"
     ]
    }
   ],
   "source": [
    "# check if there is any duplicate links\n",
    "print(len(set(all_links)), len(all_links))\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write it to file txt\n",
    "kos_url_file = open('olx_urls31.txt',  'w',  encoding=\"utf-8\")\n",
    "for url in kos_urls:\n",
    "    kos_url_file.write('{}\\n'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = list(set(kos_urls)) # add non duplicate links to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos_url_file = open('.\\olx\\olx_urls.txt',  'w',  encoding=\"utf-8\") # all links from link1 to link31\n",
    "for url in links:\n",
    "    kos_url_file.write('{}\\n'.format(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is duplicate links\n",
    "def load_multiple_links():\n",
    "    links = []\n",
    "\n",
    "    max = 31\n",
    "\n",
    "    for i in range(1, max+1):\n",
    "        urls = open('olx_urls{}.txt'.format(i),  'r',  encoding=\"utf-8\")\n",
    "\n",
    "        for url in urls:\n",
    "            links.append(url.replace('\\n', ''))\n",
    "        \n",
    "    print(len(links), len(set(links)))\n",
    "    return links\n",
    "\n",
    "# no duplicate links\n",
    "def load_links():\n",
    "    links = []\n",
    "    urls = open('.\\olx\\olx_urls.txt',  'r',  encoding=\"utf-8\")\n",
    "    for url in urls:\n",
    "        links.append(url.replace('\\n', ''))\n",
    "        \n",
    "    print(len(links), len(set(links)))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11202 11202\n"
     ]
    }
   ],
   "source": [
    "links = load_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batching\n",
    "url_batch_1 = links[:1438]\n",
    "url_batch_2 = links[1438:2500]\n",
    "url_batch_3 = links[2500:3500]\n",
    "url_batch_4 = links[3500:4500]\n",
    "url_batch_5 = links[4500:5500]\n",
    "url_batch_6 = links[5500:6500]\n",
    "url_batch_7 = links[6500:7500]\n",
    "url_batch_8 = links[7500:8500]\n",
    "url_batch_9 = links[8500:9500]\n",
    "url_batch_10 = links[9500:10500]\n",
    "url_batch_11 = links[10500:]\n",
    "\n",
    "print(len(url_batch_1) + len(url_batch_2) + len(url_batch_3) + len(url_batch_4) + len(url_batch_5) + len(url_batch_6) + len(url_batch_7) + len(url_batch_8) + len(url_batch_9) + len(url_batch_10) + len(url_batch_11))\n",
    "print(len(url_batch_1) , len(url_batch_2) , len(url_batch_3) , len(url_batch_4) , len(url_batch_5) , len(url_batch_6) , len(url_batch_7) , len(url_batch_8) , len(url_batch_9) , len(url_batch_10) , len(url_batch_11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "1400 1400 1200\n"
     ]
    }
   ],
   "source": [
    "# 6500 - 10500\n",
    "url_batch_7 = links[6500:7900]\n",
    "url_batch_8 = links[7900:9300]\n",
    "url_batch_9 = links[9300:10500]\n",
    "\n",
    "print(len(url_batch_7) + len(url_batch_8) + len(url_batch_9))\n",
    "print(len(url_batch_7) , len(url_batch_8) , len(url_batch_9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring function for scraping kost data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_multiple_links(links):\n",
    "    titles, owners, locations, phones = [], [], [], []\n",
    "    # login \n",
    "    login_url = 'https://www.olx.co.id/'\n",
    "    login_data = {\n",
    "        'email': 'your email',\n",
    "        'password': 'your password'\n",
    "    }\n",
    "    chrome_driver_path = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "\n",
    "    # login \n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.get(login_url)\n",
    "    log_in = driver.find_element_by_xpath('//span[contains(text(), \"Login\")]')\n",
    "    log_in.click()\n",
    "    time.sleep(2)\n",
    "    login_by_email = driver.find_element_by_xpath(\"//span[.='Login/Daftar dengan Email']\")\n",
    "    login_by_email.click()\n",
    "    time.sleep(3)\n",
    "    email_field = driver.find_element_by_name('email')\n",
    "    email_field.send_keys(login_data['email'])\n",
    "    email_field.submit()\n",
    "    time.sleep(5)\n",
    "    pswd_field = driver.find_element_by_name('password')\n",
    "    pswd_field.send_keys(login_data['password'])\n",
    "    pswd_field.submit()\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n",
    "    bar = pyprind.ProgBar(len(links), track_time=True, title='Scraping kos data from olx')\n",
    "\n",
    "    # try get dta each link\n",
    "    for link in links:\n",
    "        try:\n",
    "            # login again if logged out in the middle of process\n",
    "            if len(driver.find_element_by_xpath('//span[contains(text(), \"Login\")]').text) > 0:\n",
    "                log_in = driver.find_element_by_xpath('//span[contains(text(), \"Login\")]')\n",
    "                log_in.click()\n",
    "                time.sleep(2)\n",
    "                login_by_email = driver.find_element_by_xpath(\"//span[.='Login/Daftar dengan Email']\")\n",
    "                login_by_email.click()\n",
    "                time.sleep(3)\n",
    "                email_field = driver.find_element_by_name('email')\n",
    "                email_field.send_keys(login_data['email'])\n",
    "                email_field.submit()\n",
    "                time.sleep(5)\n",
    "                pswd_field = driver.find_element_by_name('password')\n",
    "                pswd_field.send_keys(login_data['password'])\n",
    "                pswd_field.submit()\n",
    "                time.sleep(3)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        driver.get(link)\n",
    "        try:\n",
    "            # click show number to make page show it\n",
    "            show_number = driver.find_element_by_xpath('//div[contains(text(), \"Tampilkan nomor\")]')\n",
    "            parent_class = show_number.find_element_by_xpath(\"./..\").get_attribute('class')\n",
    "            show_number.click()\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        page = BeautifulSoup(driver.page_source, 'html.parser') # load to beautifulsoup type\n",
    "        # get data, if null then '-'\n",
    "        try:        \n",
    "            title = page.find('h1', class_='_3rJ6e').text\n",
    "        except:\n",
    "            title = '-'\n",
    "        \n",
    "        try:\n",
    "            location = page.find('span', class_='_2FRXm').text\n",
    "        except:\n",
    "            location = '-'\n",
    "            \n",
    "        try:\n",
    "            owner = page.find('div', class_='_3oOe9').text\n",
    "        except:\n",
    "            owner = '-'\n",
    "            \n",
    "        try:\n",
    "            phone = page.find('div', class_='_1uXYV').text\n",
    "        except:\n",
    "            phone = '-'\n",
    "            \n",
    "        # save to list\n",
    "        titles.append(title)\n",
    "        owners.append(owner)\n",
    "        locations.append(location)\n",
    "        phones.append(phone)\n",
    "        delays = [2, 3, 4]\n",
    "        delay = np.random.choice(delays)\n",
    "        time.sleep(delay)\n",
    "        bar.update()\n",
    "        \n",
    "    driver.close()   \n",
    "    return titles, locations, owners, phones\n",
    "\n",
    "def scraping_single_link(link):\n",
    "    # titles, owners, locations, phones = [], [], [], []\n",
    "    login_url = 'https://www.olx.co.id/'\n",
    "    login_data = {\n",
    "        'email': 'your email',\n",
    "        'password': 'your password'\n",
    "    }\n",
    "    chrome_driver_path = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "\n",
    "    # login \n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.get(login_url)\n",
    "    log_in = driver.find_element_by_xpath('//span[contains(text(), \"Login\")]')\n",
    "    log_in.click()\n",
    "    time.sleep(2)\n",
    "    login_by_email = driver.find_element_by_xpath(\"//span[.='Login/Daftar dengan Email']\")\n",
    "    login_by_email.click()\n",
    "    time.sleep(3)\n",
    "    email_field = driver.find_element_by_name('email')\n",
    "    email_field.send_keys(login_data['email'])\n",
    "    email_field.submit()\n",
    "    time.sleep(5)\n",
    "    pswd_field = driver.find_element_by_name('password')\n",
    "    pswd_field.send_keys(login_data['password'])\n",
    "    pswd_field.submit()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    driver.get(link)\n",
    "    try:\n",
    "        show_number = driver.find_element_by_xpath('//div[contains(text(), \"Tampilkan nomor\")]')\n",
    "        parent_class = show_number.find_element_by_xpath(\"./..\").get_attribute('class')\n",
    "        show_number.click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    page = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    try:        \n",
    "        title = page.find('h1', class_='_3rJ6e').text\n",
    "    except:\n",
    "        title = '-'\n",
    "    \n",
    "    try:\n",
    "        location = page.find('span', class_='_2FRXm').text\n",
    "    except:\n",
    "        location = '-'\n",
    "        \n",
    "    try:\n",
    "        owner = page.find('div', class_='_3oOe9').text\n",
    "    except:\n",
    "        owner = '-'\n",
    "        \n",
    "    try:\n",
    "        phone = page.find('div', class_='_1uXYV').text\n",
    "    except:\n",
    "        phone = '-'\n",
    "        \n",
    "    driver.close() \n",
    "    return title, location, owner, phone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping kost data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = url_batch_9[-71:] # get from batch link\n",
    "titles, owners, locations, phones = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for login function\n",
    "def login_olx(login_data, driver):\n",
    "    log_in = driver.find_element(By.XPATH, '//span[contains(text(), \"Login\")]')\n",
    "    log_in.click()\n",
    "    time.sleep(2)\n",
    "    login_by_email = driver.find_element(By.XPATH, \"//span[.='Login/Daftar dengan Email']\")\n",
    "    login_by_email.click()\n",
    "    time.sleep(3)\n",
    "    email_field = driver.find_element(By.NAME, 'email')\n",
    "    email_field.send_keys(login_data['email'])\n",
    "    email_field.submit()\n",
    "    time.sleep(3)\n",
    "    pswd_field = driver.find_element(By.NAME, 'password')\n",
    "    pswd_field.send_keys(login_data['password'])\n",
    "    pswd_field.submit()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping kos data from olx\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:47\n"
     ]
    }
   ],
   "source": [
    "# without function that already declared\n",
    "\n",
    "chrome_driver_path = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "\n",
    "# login \n",
    "login_url = 'https://www.olx.co.id/'\n",
    "login_data = {\n",
    "    'email': 'your email',\n",
    "    'password': 'your password'\n",
    "}\n",
    "\n",
    "# login \n",
    "driver = webdriver.Chrome(service=Service(chrome_driver_path))\n",
    "driver.get(login_url)\n",
    "time.sleep(1)\n",
    "login_olx(login_data, driver)\n",
    "\n",
    "bar = pyprind.ProgBar(len(links), track_time=True, title='Scraping kos data from olx')\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        if len(driver.find_element(By.XPATH, '//span[contains(text(), \"Login\")]').text) > 0:\n",
    "            time.sleep(1)\n",
    "            login_olx(login_data, driver)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        driver.get(link)\n",
    "        try:\n",
    "            if len(driver.find_element(By.XPATH, '//span[contains(text(), \"Ups...\")]').text) > 0:\n",
    "                title = '-'\n",
    "                location = '-'\n",
    "                owner = '-'\n",
    "                phone = '-'\n",
    "        except:\n",
    "            elem = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME , \"_2b6xv\")))\n",
    "            show_number = driver.find_element(By.XPATH, '//div[contains(text(), \"Tampilkan nomor\")]')\n",
    "\n",
    "            parent_class = show_number.find_element(By.XPATH, \"./..\").get_attribute('class')\n",
    "            show_number.click()\n",
    "\n",
    "            time.sleep(3)\n",
    "            try:\n",
    "                page = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                \n",
    "                try:        \n",
    "                    title = page.find('h1', class_='_3rJ6e').text\n",
    "                except:\n",
    "                    title = '-'\n",
    "                \n",
    "                try:\n",
    "                    location = page.find('span', class_='_2FRXm').text\n",
    "                except:\n",
    "                    location = '-'\n",
    "                    \n",
    "                try:\n",
    "                    owner = page.find('div', class_='_3oOe9').text\n",
    "                except:\n",
    "                    owner = '-'\n",
    "                    \n",
    "                try:\n",
    "                    phone = page.find('div', class_='_1uXYV').text\n",
    "                except:\n",
    "                    phone = '-'\n",
    "            except:\n",
    "                title = '-'\n",
    "                location = '-'\n",
    "                owner = '-'\n",
    "                phone = '-'\n",
    "    except:\n",
    "        title = '-'\n",
    "        location = '-'\n",
    "        owner = '-'\n",
    "        phone = '-'\n",
    "    \n",
    "    titles.append(title)\n",
    "    owners.append(owner)\n",
    "    locations.append(location)\n",
    "    phones.append(phone)\n",
    "    delays = [1, 2]\n",
    "    delay = np.random.choice(delays)\n",
    "    time.sleep(delay)\n",
    "    bar.update()\n",
    "    \n",
    "driver.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 61 50 59 58\n",
      "71 71 71 71 71\n"
     ]
    }
   ],
   "source": [
    "# check duplicate data\n",
    "print(len(links), len(set(titles)), len(set(locations)), len(set(owners)), len(set(phones)))\n",
    "print(len(links), len(titles), len(locations), len(owners), len(phones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "type = 'file_olx_'\n",
    "batch = '9_2'\n",
    "\n",
    "output_path = '.\\olx\\{}_{}.xlsx'.format(type, batch)\n",
    "pd.DataFrame({'Judul':titles, 'Lokasi':locations, 'Owner Kos':owners, 'No Hp':phones, 'URL Kos':links}).to_excel(output_path, index=False, engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "excl_list = []\n",
    "\n",
    "for i in range(1, 10+1):\n",
    "    if i != 9:\n",
    "        excl_list.append(pd.read_excel('.\\olx\\\\file_olx_{}.xlsx'.format(i)))\n",
    "    else:\n",
    "        excl_list.append(pd.read_excel('.\\olx\\\\file_olx_{}.xlsx'.format(i))[:-71])\n",
    "\n",
    "excl_merged = pd.DataFrame()\n",
    "\n",
    "for excl_file in excl_list:\n",
    "    excl_merged = excl_merged.append(\n",
    "        excl_file, ignore_index=True)\n",
    "\n",
    "excl_merged.to_excel('.\\olx\\\\file_olx.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('.\\olx\\\\file_olx.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11203\n",
      "6472\n"
     ]
    }
   ],
   "source": [
    "print(len(df['URL Kos'].unique()))\n",
    "print(len(df['No Hp'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bd77b28dae0335d82a29543ac23f66b40c0df6f9ea51368662aa49cd1fb1eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
